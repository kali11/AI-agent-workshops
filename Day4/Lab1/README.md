# Lab 1: Building multi-agent app with AutoGen
In this lab you will learn how to build a multi-agent app using AutoGen framework

## Prerequisutes:
- OpenAI API key with a few Euros credits
- Google account

## Task 1: Set-up
1. Open Google Colab: https://colab.research.google.com/
2. Create new notebook, name it eg. **Workshop4 - la1**
3. First, we need to install dependencies. In the first cell type and run:

```python
!pip install "pyautogen>=0.2.18"
```

4. Create a configuration for all AI agents:

```python
from google.colab import userdata

config = {
    "config_list": [
        {
            "model": "gpt-4o",
            "api_key": userdata.get('openai_key')
        }
    ]
}
```

## Task 2: Create simple Two-Agent Chat

1. First, let's create an assistant agent. This type of agent doesn't require human input and it cannot execute code. However it can generate the code.

```python
import os
from autogen import AssistantAgent, UserProxyAgent

assistant = AssistantAgent(name="assistant", llm_config=config)
```

2. AssistantAgent comes with default system message. You can examine it:

```python
print(assistant.system_message)
```

3. Human Input Mode is set to **NEVER**. That means that this agent will never ask for user input. Verify this:

```python
print(assistant.human_input_mode)
```

4. Now, let's create a code executor. In AutoGen we can execute the code:
- locally
- in Docker (safest way)
- in Jupyter
For now let's use local mode:

```python
from autogen.coding import LocalCommandLineCodeExecutor

code_executor = LocalCommandLineCodeExecutor()
```

5. Then create a UserProxyAgent. This type of agent doesn't use LLM but it can execute the code. By default it asks user before execution:

```python
user_proxy = UserProxyAgent(
    name="user_proxy",
    code_execution_config={"executor": code_executor}
    )
```

6. Because this agent doesn't use LLM, the system message is empty:

```python
print(user_proxy.system_message)
```

7. Now let's give a task to our agents:

```python
user_proxy.initiate_chat(
    assistant,
    message="""What is the current bitcoin price? Draw a chart of bitcoin price from last 6 month and save to file.""",
)
```

8. Whenever to **user_proxy** agent is called, you will need to hit **Enter** to continue. But in the end you should get two new files. One with the chart and second with python code.

9. You can modify this behaviour and make those agents fully autonomous:

```python
user_proxy = UserProxyAgent(
    name="user_proxy",
    code_execution_config={"executor": code_executor},
    human_input_mode="NEVER"
    )
```

10. Run the chat again:

```python
user_proxy.initiate_chat(
    assistant,
    message="""What is the current bitcoin price? Draw a chart of bitcoin price from last 6 month and save to file.""",
)
```

## Task 3: Create a group of agents
In this task a group of agents will work together to write a blog post.

1. First, let's create a planner, that will plan how to blog post should be structured:

```python
planner = AssistantAgent(
    name="Planner",
    description="Plans the whole work and split it into sub-tasks",
    llm_config=config,
    system_message="""You are a helpful AI assistant. Your role is to create tasks.
    You suggest coding and reasoning steps for another AI assistant to accomplish a task.
    Do not suggest concrete code. For any action beyond writing code or reasoning, convert it to a step that can be implemented by writing code.
    For example, browsing the web can be implemented by writing code that reads and prints the content of a web page.
    Finally, inspect the execution result. If the plan is not good, suggest a better plan.
    If the execution is wrong, analyze the error and suggest a fix. When the plan is done - TERMINATE""",
    is_termination_msg=lambda msg: "TERMINATE" in msg["content"].lower()
)
```

2. Writer:

```python
writer = AssistantAgent(
    name="Writer",
    description="Writes content",
    llm_config=config,
    system_message="""Content writer. You follow an approved plan. You write a blog post based
    on a given plan and topic. You should include code snippets. Write the blog post in a separate file.
    """,
)
```

3. Critic:

```python
critic = AssistantAgent(
    name="Critic",
    description="Checks and analyze text",
    llm_config=config,
    system_message="""Critic. You are a helpful AI assistant. Your role is to check text generated by Writer
    and report mistakes and places for improvemement. When the blog post is ok - TERMINATE.
    """,
    is_termination_msg=lambda msg: "TERMINATE" in msg["content"].lower()
)
```

4. Executor:

```python
executor = UserProxyAgent(
    name="Executor",
    description="Execudes Python code",
    human_input_mode="NEVER",
    code_execution_config={"executor": code_executor}
)
```

5. User Proxy:

```python
user_admin = UserProxyAgent(
    name="Admin",
    system_message="A human admin.",
    code_execution_config=False,
    human_input_mode="TERMINATE"
)
```

6. Now, let's create a group chat and a manager. They are responsible for managing the whole conversation. We limit the conversation to 25 messages.
By default AutoGen automatically selects which agent should talk next. It uses mainly **description** attribute of each agent. Other options of an order are: **round robin**, **random**, **manual**.

```python
from autogen import GroupChat, GroupChatManager

groupchat = GroupChat(
    agents=[user_admin, planner, developer, tester, executor], messages=[], max_round=25
)
manager = GroupChatManager(groupchat=groupchat, llm_config=config)
```

7. Run the group:

```python
user_admin.initiate_chat(
    manager,
    message="""
Write a blog post about a GPT function calling. The post should contain one example. 
"""
)
```

8. Try to ask different question!

## End Lab